{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. 载入CIFAR10数据集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"./data/datasets\"\n",
    "cifar10_train = datasets.CIFAR10(\n",
    "    DATA_PATH,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4915, 0.4823, 0.4468],\n",
    "                             [0.2470, 0.2435, 0.2616],),\n",
    "    ]),\n",
    ")\n",
    "cifar10_val = datasets.CIFAR10(\n",
    "    DATA_PATH,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4915, 0.4823, 0.4468],\n",
    "                             [0.2470, 0.2435, 0.2616],),\n",
    "    ]),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "(10000, 2000)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 本例只需要区分airplane和bird\n",
    "# 因此从整个数据集中抽取airplane和bird\n",
    "label_map = {0: 0, 2: 1}  # 原始数据集中 0: airplane 2:bird\n",
    "cifar2_train = [(img, label_map[label]) for img, label in cifar10_train if label in (0, 2)]\n",
    "cifar2_val = [(img, label_map[label]) for img, label in cifar10_val if label in (0, 2)]\n",
    "len(cifar2_train), len(cifar2_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "# 使用DataLoader的两个好处：\n",
    "# 1. 可以指定batch_size\n",
    "# 2. 可以在每个epoch开始前shuffle整个数据集\n",
    "BATCH_SIZE = 64\n",
    "train_loader = torch.utils.data.DataLoader(cifar2_train, batch_size=BATCH_SIZE, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Softmax"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.0321, 0.0871, 0.2369, 0.6439])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Softmax：将一个向量转换使其符合概率分布\n",
    "t1 = torch.tensor([1., 2., 3., 4.])\n",
    "softmax = torch.nn.Softmax(dim=-1)  # 指定Softmax操作的维度\n",
    "softmax(t1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.0321, 0.0871, 0.2369, 0.6439],\n        [0.0321, 0.0871, 0.2369, 0.6439]])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.tensor([[1., 2., 3., 4.],\n",
    "                   [1., 2., 3., 4.]])\n",
    "softmax(t2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-3.4402, -2.4402, -1.4402, -0.4402])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LogSoftmax：对Softmax的结果取对数\n",
    "# 解决了当概率趋于0时求log易出错的问题\n",
    "t1 = torch.tensor([1., 2., 3., 4.])\n",
    "torch.nn.LogSoftmax(dim=-1)(t1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-3.4402, -2.4402, -1.4402, -0.4402])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(softmax(t1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. NLL(negative log likelihood)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.6360, -0.0668, -0.0512,  0.0691],\n        [-1.5530, -0.4829, -1.2019,  0.0383],\n        [ 1.3670, -0.8276, -0.6638,  1.0416]])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 假设神经网络输出的shape为(3, 4)，3是图片数量，4是分类个数\n",
    "out = torch.randn(3, 4)\n",
    "out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-1.8849, -1.3157, -1.3001, -1.1798],\n        [-2.3269, -1.2568, -1.9758, -0.7356],\n        [-0.6754, -2.8701, -2.7063, -1.0008]])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = torch.nn.LogSoftmax(dim=-1)(out)\n",
    "tmp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.7756)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLL = - sum(log(对应类别的prob))\n",
    "loss = torch.nn.NLLLoss()\n",
    "target = torch.tensor([0, 3, 2])  # 3张图片对应的类别\n",
    "loss(input=tmp, target=target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.7756)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(tmp[0][0] + tmp[1][3] + tmp[2][2]) / 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Cross Entropy Loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.7756)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nn.CrossEntropyLoss即为nn.LogSoftmax和nn.NLLLoss的整合\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "loss(input=out, target=target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. 创建网络层"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(32 * 32 * 3, 1024),\n",
    "    torch.nn.Tanh(),\n",
    "    torch.nn.Linear(1024, 512),\n",
    "    torch.nn.Tanh(),\n",
    "    torch.nn.Linear(512, 256),\n",
    "    torch.nn.Tanh(),\n",
    "    torch.nn.Linear(256, 128),\n",
    "    torch.nn.Tanh(),\n",
    "    torch.nn.Linear(128, 64),\n",
    "    torch.nn.Tanh(),\n",
    "    torch.nn.Linear(64, 2),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. 训练"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 0.588484963414016\n",
      "epoch: 1 loss: 0.5014044893015722\n",
      "epoch: 2 loss: 0.48209624286669833\n",
      "epoch: 3 loss: 0.4712113159097684\n",
      "epoch: 4 loss: 0.46001220015203875\n",
      "epoch: 5 loss: 0.4497708412492351\n",
      "epoch: 6 loss: 0.44224643764222504\n",
      "epoch: 7 loss: 0.43368932225142315\n",
      "epoch: 8 loss: 0.4246966914766154\n",
      "epoch: 9 loss: 0.4163347775009787\n",
      "epoch: 10 loss: 0.4098209279358007\n",
      "epoch: 11 loss: 0.4020033873570193\n",
      "epoch: 12 loss: 0.39598155515209127\n",
      "epoch: 13 loss: 0.3864271598067253\n",
      "epoch: 14 loss: 0.38284256817049284\n",
      "epoch: 15 loss: 0.36985874944811414\n",
      "epoch: 16 loss: 0.36772235611062143\n",
      "epoch: 17 loss: 0.35801338504074487\n",
      "epoch: 18 loss: 0.3564667286956386\n",
      "epoch: 19 loss: 0.34396797428085546\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-2\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=lr)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "n_epochs = 20\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    losses = []\n",
    "    for imgs, labels in train_loader:\n",
    "        # img: [b, 3, 32, 32] -> [b, -1]\n",
    "        # out: [b, 2]\n",
    "        batch_size = imgs.shape[0]\n",
    "        out = model(imgs.reshape(batch_size, -1))\n",
    "        loss = loss_fn(input=out, target=labels)\n",
    "\n",
    "        # 清零梯度信息\n",
    "        optimizer.zero_grad()\n",
    "        # 计算loss的梯度\n",
    "        loss.backward()\n",
    "        # 用梯度更新模型参数\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(float(loss))\n",
    "\n",
    "    print(f\"epoch: {epoch} loss: {sum(losses) / len(losses)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7. 测试"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6855\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "correct = total = 0\n",
    "\n",
    "# 在inference过程，需要禁止梯度计算\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.reshape(batch_size, -1))\n",
    "        _, pred = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((pred == labels).sum())\n",
    "\n",
    "    print(f\"Accuracy: {correct / total}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-418948df",
   "language": "python",
   "display_name": "PyCharm (ACM-Py)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}